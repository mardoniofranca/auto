{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/mardoniofranca/work/env/lib/python3.6/site-packages (2.3.2)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.0.6-cp36-cp36m-manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.9 MB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.4-cp36-cp36m-manylinux2014_x86_64.whl (9.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.2 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (2.25.0)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.3\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
      "  Downloading spacy_legacy-3.0.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp36-cp36m-manylinux2014_x86_64.whl (456 kB)\n",
      "\u001b[K     |████████████████████████████████| 456 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: jinja2 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (3.7.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (1.19.5)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Downloading thinc-8.0.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620 kB)\n",
      "\u001b[K     |████████████████████████████████| 620 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.5.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 34 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (47.1.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.1.0)\n",
      "Requirement already satisfied: six in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses<1.0,>=0.6\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from thinc<8.1.0,>=8.0.3->spacy) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from contextvars<3,>=2.4->thinc<8.1.0,>=8.0.3->spacy) (0.14)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/mardoniofranca/work/env/lib/python3.6/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=17a94cd85d2088ebbdd38dd04d389fb25f04686cc0e824ed9baffc0a631e4211\n",
      "  Stored in directory: /home/mardoniofranca/.cache/pip/wheels/88/2a/d4/f2e9023989d4d4b3574f268657cb6cd23994665a038803f547\n",
      "Successfully built smart-open\n",
      "Installing collected packages: dataclasses, catalogue, wasabi, typer, srsly, smart-open, pydantic, thinc, spacy-legacy, pathy, spacy\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 0.8.0\n",
      "    Uninstalling wasabi-0.8.0:\n",
      "      Successfully uninstalled wasabi-0.8.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 1.0.2\n",
      "    Uninstalling srsly-1.0.2:\n",
      "      Successfully uninstalled srsly-1.0.2\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 4.0.1\n",
      "    Uninstalling smart-open-4.0.1:\n",
      "      Successfully uninstalled smart-open-4.0.1\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 7.4.1\n",
      "    Uninstalling thinc-7.4.1:\n",
      "      Successfully uninstalled thinc-7.4.1\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 2.3.2\n",
      "    Uninstalling spacy-2.3.2:\n",
      "      Successfully uninstalled spacy-2.3.2\n",
      "Successfully installed catalogue-2.0.4 dataclasses-0.8 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.6 srsly-2.4.1 thinc-8.0.5 typer-0.3.2 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Meu nome é Marcelo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meu, nome, é, Marcelo, .]\n"
     ]
    }
   ],
   "source": [
    "print([d for d in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meu', 'nome', 'é', 'Marcelo', '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu Meu\n",
      "nome nome\n",
      "é ser\n",
      "Marcelo Marcelo\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"c6879bca036f411da0961e940d100ef5-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Meu</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">nome</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">é</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Marcelo.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6879bca036f411da0961e940d100ef5-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6879bca036f411da0961e940d100ef5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6879bca036f411da0961e940d100ef5-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6879bca036f411da0961e940d100ef5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6879bca036f411da0961e940d100ef5-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6879bca036f411da0961e940d100ef5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# viewing sentece's structure\n",
    "from spacy import displacy\n",
    "from IPython.display import SVG, display\n",
    "def showSVG(s):\n",
    "  display(SVG(s))\n",
    "\n",
    "graph01 = displacy.render(doc)\n",
    "showSVG(graph01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXT: Meu  -- é caracter?: True é pontuacao?: False está em caixa baixa?: False\n",
      "TXT: nome  -- é caracter?: True é pontuacao?: False está em caixa baixa?: True\n",
      "TXT: é  -- é caracter?: True é pontuacao?: False está em caixa baixa?: True\n",
      "TXT: Marcelo  -- é caracter?: True é pontuacao?: False está em caixa baixa?: False\n",
      "TXT: .  -- é caracter?: False é pontuacao?: True está em caixa baixa?: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print('TXT:',token.text, ' -- é caracter?:',token.is_alpha, \n",
    "        'é pontuacao?:', token.is_punct, 'está em caixa baixa?:', token.is_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A similaridade entre \" O \" e \" O \" :  1.0\n",
      "A similaridade entre \" O \" e \" doce \" :  -0.029433718\n",
      "A similaridade entre \" O \" e \" de \" :  -0.20175445\n",
      "A similaridade entre \" O \" e \" batata \" :  -0.15005141\n",
      "A similaridade entre \" O \" e \" doce \" :  -0.18617855\n",
      "A similaridade entre \" doce \" e \" O \" :  -0.029433718\n",
      "A similaridade entre \" doce \" e \" doce \" :  1.0\n",
      "A similaridade entre \" doce \" e \" de \" :  0.00390967\n",
      "A similaridade entre \" doce \" e \" batata \" :  0.3249701\n",
      "A similaridade entre \" doce \" e \" doce \" :  1.0\n",
      "A similaridade entre \" de \" e \" O \" :  -0.20175445\n",
      "A similaridade entre \" de \" e \" doce \" :  0.00390967\n",
      "A similaridade entre \" de \" e \" de \" :  1.0\n",
      "A similaridade entre \" de \" e \" batata \" :  0.1782919\n",
      "A similaridade entre \" de \" e \" doce \" :  0.035783026\n",
      "A similaridade entre \" batata \" e \" O \" :  -0.15005141\n",
      "A similaridade entre \" batata \" e \" doce \" :  0.3249701\n",
      "A similaridade entre \" batata \" e \" de \" :  0.1782919\n",
      "A similaridade entre \" batata \" e \" batata \" :  1.0\n",
      "A similaridade entre \" batata \" e \" doce \" :  0.4475806\n",
      "A similaridade entre \" doce \" e \" O \" :  -0.18617855\n",
      "A similaridade entre \" doce \" e \" doce \" :  1.0\n",
      "A similaridade entre \" doce \" e \" de \" :  0.035783026\n",
      "A similaridade entre \" doce \" e \" batata \" :  0.4475806\n",
      "A similaridade entre \" doce \" e \" doce \" :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mardoniofranca/work/env/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# similarity between two words\n",
    "# I did metrics with all token's position\n",
    "d2 = [token for token in nlp('O doce de batata doce')]\n",
    "for a in d2:\n",
    "  for b in d2:\n",
    "    print('A similaridade entre \"',a, '\" e \"',b, '\" : ', a.similarity(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Meu', 90, 'DET'),\n",
       " ('nome', 92, 'NOUN'),\n",
       " ('é', 87, 'AUX'),\n",
       " ('Marcelo', 96, 'PROPN'),\n",
       " ('.', 97, 'PUNCT')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structure POS (Part-of-Speech)\n",
    "[(token.text, token.pos, token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN [Nome Proprio] Salvador ANTES DE UM VERBO: parecer\n",
      "PROPN [Nome Proprio] Recife ANTES DE UM VERBO: aparentar\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Salvador parece ser uma grande cidade. Recife aparenta ser grande tambem. Aguas de Lindoya, nao')\n",
    "\n",
    "# TOKENIZING\n",
    "for token in doc:\n",
    "    # check if token POS is PROPN\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        # and check if token POS [position + 1] is VERB\n",
    "        if doc[token.i + 1].pos_ == \"VERB\":\n",
    "            print(f\"PROPN [Nome Proprio] {token.text} ANTES DE UM VERBO: {doc[token.i + 1].lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
